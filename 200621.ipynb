{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First run equilibration steps on MD tutorial\n",
    "- need these files to start:\n",
    "    - \n",
    "- First run scaling tests\n",
    "- then run a \"long\" job and split up\n",
    "    - only run like 10 ns or so, but pretend its like 1000\n",
    "- extend the run\n",
    "- run duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook will run through production MD runs for a system with multiple protein chains and a novel residue (Ser with a cyanylated Ppant arm attached > PCN). I will run through the notebook and leave all of my files in this directory. If you want to try running through it on your own, I suggest copying this directory (200621), then deleting the files and changing the name of the jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most of these files were produced in during the setup and equilibration steps of the MD tutorial. You can get them by copying over the files after running the notebook. I did that and then changed the names to match the date I did this (200621). "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "200621.ipynb\t\t\t  200621_topol.top\n",
    "200621_npt.tpr\t\t\t  charmm36-190509.ff\n",
    "200621_topol_Protein_chain_A.itp  README.md\n",
    "200621_topol_Protein_chain_B.itp  residuetypes.dat\n",
    "200621_topol_Protein_chain_C.itp  Untitled.ipynb\n",
    "200621_topol_Protein_chain_D.itp\n",
    "200621_npt.gro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Tests"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Run the following in a terminal window\n",
    "\n",
    "# open a secure shell on stampede2:\n",
    "ssh coire@stampede2.tacc.utexas.edu\n",
    "\n",
    "#move to the scratch directory:\n",
    "cds\n",
    "\n",
    "# make a new directory and move to it:\n",
    "mkdir 200621\n",
    "cd 200621\n",
    "\n",
    "# check location of new directory:\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to running a long job on stampede2 is to run several short jobs using different numbers of nodes. Stampede lets you choose how many processors you want to spread your job out on. In general, more processors means a faster run, but there are several things to consider. First, when a job is more spread out, it often becomes less efficient- increasing the numberof processors by 100% could increase the speed by only 50%. Second, a less efficient job is more expensive to run. We are charged by computer time, not by clock time. So a job that is run on 2 nodes that takes 5 hours to run is more expensive to us than a job on 1 node that takes 9 hours to run. \n",
    "\n",
    "Also, stampede2 lets a job run for a maximum of 48 hours. After 48 hours, it kicks the job off of the processor, regardless of its status. If you have a long MD job that will take more than 48 hours to run, you need to split it up into multiple runs (I will do this later in the norebook). We can get a good idea of how long we can run in 48 hours by running these small jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need an mdp file that can be used for all of the scaling runs. We should edit it so that it specifies a ~1ns run\n",
    "\n",
    "[200621_scale.mdp](200621_scale.mdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need script files that can be run on stampede. The following lines of code tell stampede what to do with the srcipt. \n",
    "\n",
    "|Code in Script|comment in the script|additional notes|\n",
    "|-|-|-|\n",
    "|```#SBATCH -J 21_1n```|```# Job name```|how jobs are described when they are running. must be descriptive and less than 6 characters|\n",
    "|```#SBATCH -o /scratch/06442/coire/200621/200621_1node.o%j``` |```# Name of stdout output file```|location and name of output file. leave the \".o%j\" at the end|\n",
    "|```#SBATCH -e /scratch/06442/coire/200621/200621_1node.e%j``` |```# Name of stderr error file```|location and name of error file. leave the \".e%j\" at the end|\n",
    "|```#SBATCH -p normal``` |```# Queue (partition) name```|type of node used. Do not change|\n",
    "|```#SBATCH -N 1 ``` |```# Total # of nodes```|Number of nodes used. only use 2<sup>n</sup> nodes (1, 2, 4, 8, 16, etc)|\n",
    "|```#SBATCH -n 64``` |```# Total # of mpi tasks (or number of MPI processes)```|number of mpi tasks used, must change with number of nodes (mpi tasks = nodes*64)|\n",
    "|```#SBATCH -t 48:00:00``` |```# Run time (hh:mm:ss)```|clock time allocated for run. Keep at 48 hours. If job runs over allocated time, job will be kicked off|\n",
    "|```#SBATCH --mail-user=cgavinhann@haverford.edu``` |```# E-mail address```|alerts sent to this email when job starts and finishes|\n",
    "|```#SBATCH --mail-type=all``` |```# Send email at begin and end of job (none for no emails)```|changes email settings. DO not change|\n",
    "|```#SBATCH -A TG-MCB180055``` |```# Allocation name (req'd if you have more than 1)```|Do not change|\n",
    "\n",
    "\n",
    "The next lines are the actual script and should also be modified to fit your needs\n",
    "\n",
    "\n",
    "- [200621_1node.sh](200621_1node.sh)\n",
    "- [200621_2node.sh](200621_2node.sh)\n",
    "- [200621_4node.sh](200621_4node.sh)\n",
    "- [200621_8node.sh](200621_8node.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy over files to Stampede\n",
    "!mkdir ToStampede/\n",
    "! mv 200621_scale.mdp ./ToStampede\n",
    "! mv 200621_npt.gro ./ToStampede\n",
    "! mv charmm36-190509.ff/ ./ToStampede\n",
    "! mv *topol* ./ToStampede # all of the topology files\n",
    "! mv residuetypes.dat ./ToStampede\n",
    "! mv *.sh ./ToStampede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all files in ToStampede/ to directory in stampede\n",
    "#in terminal window:\n",
    "scp ToStampede/* coire@stampede2.tacc.utexas.edu:/scratch/06442/coire/200621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv ToStampede/* ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run each script on stampede by running the command \"sbatch _scriptName.sh_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the bottom of the \".e...\" output file for each run and construct the following table. Choose how many nodes to use in your long simulation by balancing clock time with efficiency. We are charged for jobs in node-hour units. \n",
    "\n",
    "|Nodes|clock time|(node*hr)/ns|ns/day|\n",
    "|-|-|-|-|\n",
    "|1|48:58|0.816|29.4|\n",
    "|2|30:16|1.01|47.6|\n",
    "|4|20:20|1.35|70.8|\n",
    "|8|14:52|1.984|96.7|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Run\n",
    "\n",
    "I try to not run more than 50-75% of the maximum length per day. So If I ran a 500ns simulation on 2 nodes, I would split up the run into multiple runs of 50ns (each run can be up to 48 hrs long). Because this is just an example and I don't want to use up too much computer time, I will run a 10 ns simulation split up into 5 2ns runs each using 2 nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I need an mdp file that specifies a 2ns run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp 200621_scale.mdp ./200621_md_2ns.mdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change simulation length to 2 ns\n",
    "- change the output to a .trr file using the output control lines\n",
    "    - also change the output control lines to only output only 100 ps instead of every 10 ps\n",
    "    \n",
    "[200621_md_2ns.mdp](200621_md_2ns.mdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need script files that will run a series of jobs. Use cpt files to save the simulation state between runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [200621_r1.sh](200621_r1.sh)\n",
    "- [200621_r2.sh](200621_r2.sh)\n",
    "- [200621_r3.sh](200621_r3.sh)\n",
    "- [200621_r4.sh](200621_r4.sh)\n",
    "- [200621_r5.sh](200621_r5.sh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scripts need to be submitted so that they are dependent on each other- r2 cannot run until 21 finishes and so on. Stampede allows you to do that using the \"--dependency=afterok:_jobid_\" option when submitting a job with sbatch. When the first job is submitted normally, stampede will output a jobid. That jobid is placed at the end of the dependency option when submitting the next job. The following script and python program automate the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [200621_submitJobs.sh](200621_submitJobs.sh)\n",
    "- [extractJobID.py](extractJobID.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy all script files, the mdp file, and the python file to the stampede directory. then submit all of the jobs using the single command \"bash 200621_submitJobs.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check status of the job queue with \"squeue -u username\"\n",
    "- if something goes wrong and a job fails, stop its dependencies with \"scancel jobid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
